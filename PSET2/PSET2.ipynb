{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A: Initializing the state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class State:\n",
    "    \n",
    "    def __init__(self, x_position, y_position, heading):\n",
    "        self.x_position = x_position\n",
    "        self.y_position = y_position\n",
    "        self.heading = heading\n",
    "        \n",
    "    def return_current_state(self):\n",
    "        return self.x_position, self.y_position, self.heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B: Initializing the action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Action:\n",
    "    \n",
    "    def __init__(self, move, rotation):\n",
    "        self.move = move\n",
    "        self.rotation = rotation\n",
    "        \n",
    "    def return_action(self):\n",
    "        return self.move, self.rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1C: Return the probabilty Psa(s') given pe, s, a, s'\n",
    "## 1D: return a next state s' given error probability pe, s, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### This is the Markov decision process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MarkovDecisionProcess:\n",
    "    \n",
    "    # get the length and the width of the space that we are in\n",
    "    def __init__(self, length, width):\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "    \n",
    "    # check for bound violations\n",
    "    def check_bounds(self, next_x, next_y, current_x, current_y):\n",
    "        if (next_x < 0 or next_x >= self.width):\n",
    "            next_x = current_x\n",
    "        if (next_y < 0 or next_y >= self.length):\n",
    "            next_y = current_y\n",
    "        return next_x, next_y\n",
    "    \n",
    "    #define the directions\n",
    "    left = {8,9,10}\n",
    "    right = {2,3,4}\n",
    "    up = {11,0,1}\n",
    "    down = {5,6,7}\n",
    "    \n",
    "    # find out the next step --> returns next_x, next_y, next_heading\n",
    "    def next_state_compiled(self, state, action):\n",
    "        # get x, y and heading from state\n",
    "        current_x = state.x_position\n",
    "        current_y = state.y_position\n",
    "        current_heading = state.heading\n",
    "        \n",
    "        # get move and rotation from action\n",
    "        move = action.move\n",
    "        rotation = action.rotation\n",
    "        \n",
    "        # check if heading is left, need to only change x and not y\n",
    "        if current_heading in self.left:\n",
    "            next_x = current_x - move\n",
    "            next_y = current_y\n",
    "        \n",
    "        # check if heading is right, need to only change x and not y\n",
    "        elif current_heading in self.right:\n",
    "            next_x = current_x + move\n",
    "            next_y = current_y\n",
    "        \n",
    "        # check if heading is up, need to only change y and not x\n",
    "        elif current_heading in self.up:\n",
    "            next_x = current_x\n",
    "            next_y = current_y + move\n",
    "        \n",
    "        # check if heading is down, need to only change y and not x\n",
    "        else:\n",
    "            next_x = current_x\n",
    "            next_y = current_y - move\n",
    "        \n",
    "        # need to check the bounds\n",
    "        next_x, next_y = self.check_bounds(next_x, next_y, current_x, current_y)\n",
    "        \n",
    "        # finally, need to accomodate for the rotation in heading\n",
    "        next_heading = (current_heading + rotation) % 12\n",
    "        \n",
    "        return next_x, next_y, next_heading\n",
    "    \n",
    "    # find out the next step for the movements that have the prob of error\n",
    "    def next_state_individualized(self, current_x, current_y, current_heading, move, rotation):\n",
    "        # check if heading is left, need to only change x and not y\n",
    "        if current_heading in self.left:\n",
    "            next_x = current_x - move\n",
    "            next_y = current_y\n",
    "        \n",
    "        # check if heading is right, need to only change x and not y\n",
    "        elif current_heading in self.right:\n",
    "            next_x = current_x + move\n",
    "            next_y = current_y\n",
    "        \n",
    "        # check if heading is up, need to only change y and not x\n",
    "        elif current_heading in self.up:\n",
    "            next_x = current_x\n",
    "            next_y = current_y + move\n",
    "        \n",
    "        # check if heading is down, need to only change y and not x\n",
    "        else:\n",
    "            next_x = current_x\n",
    "            next_y = current_y - move\n",
    "        \n",
    "        # need to check the bounds\n",
    "        \n",
    "        next_x, next_y = self.check_bounds(next_x, next_y, current_x, current_y)\n",
    "        \n",
    "        # finally, need to accomodate for the rotation in heading\n",
    "        next_heading = (current_heading + rotation) % 12\n",
    "        \n",
    "        return next_x, next_y, next_heading\n",
    "    \n",
    "    # find out the transition probabilities\n",
    "    def transition_probabilities(self, prob_of_error, action, current_state, next_state):\n",
    "        # get move and rotation from action\n",
    "        move = action.move\n",
    "        rotation = action.rotation\n",
    "        \n",
    "        # if we do not move, current state should equal next state. \n",
    "        if move == 0:\n",
    "            if current_state.return_current_state() == next_state.return_current_state():\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "        # in the case that we do move, need to account for the error probabilities\n",
    "        \n",
    "        if next_state.return_current_state() == self.next_state_compiled(current_state, action):\n",
    "            return 1-(2*prob_of_error)\n",
    "        else:\n",
    "            current_x = current_state.x_position\n",
    "            current_y = current_state.y_position\n",
    "            current_heading = current_state.heading\n",
    "\n",
    "            # need to check to return the prob of error\n",
    "            if next_state.return_current_state() == self.next_state_individualized(current_x, current_y, (current_heading-1)%12, move, rotation):\n",
    "                return prob_of_error\n",
    "\n",
    "            if next_state.return_current_state() == self.next_state_individualized(current_x, current_y, (current_heading+1)%12, move, rotation):\n",
    "                return prob_of_error\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    number_of_headings = 12\n",
    "    \n",
    "    # Part 1D\n",
    "    def compute_next_state(self, prob_of_error, current_state, action):\n",
    "        \n",
    "        wrong_states = []\n",
    "        # need to loop through all of the values of x, y and heading\n",
    "        for i in range(self.length):\n",
    "            for j in range(self.width):\n",
    "                for k in range(self.number_of_headings):\n",
    "                    # define the next state\n",
    "                    next_state = State(i,j,k)\n",
    "                    # find the transition probability between current state and the next state\n",
    "                    prob_of_transition = self.transition_probabilities(prob_of_error, action, current_state, next_state)\n",
    "                    # if the probability of transitioning does not equal 0, then only do we proceed. If 0, do not care\n",
    "                    if prob_of_transition != 0:\n",
    "                        # if our transition probabilty is the probability of error, it means that there was an error. Need to keep track of these next state values\n",
    "                        if prob_of_transition == prob_of_error:\n",
    "                            wrong_states.append(next_state)\n",
    "                        else:\n",
    "                            correct_next_state = next_state\n",
    "        # if I choose a random number between 0 and 1 and my number is less than 2*prob_of_error, I move in the wrong direction. If not, I move in the correct direction.\n",
    "        random_number_generated = np.random.uniform(0,1)\n",
    "        if random_number_generated < 2*prob_of_error:\n",
    "            random_index = random.randrange(len(wrong_states))\n",
    "            return wrong_states[random_index]\n",
    "        else:\n",
    "            return correct_next_state\n",
    "    def reward(self, current_state):\n",
    "        # define the lengh and the width\n",
    "        length = width = 6\n",
    "\n",
    "        # get the current x, y positions -- do not care about heading\n",
    "        current_x, current_y, _ = current_state.return_current_state()\n",
    "\n",
    "        # define the rewards\n",
    "        if current_x == 3 and current_y == 4:\n",
    "            reward = 1\n",
    "        if current_x == 0 or current_x == width-1:\n",
    "            reward = -100\n",
    "        if current_y == 0 or current_y == length-1:\n",
    "            reward = -100\n",
    "        if current_x == 2 or current_x == 4:\n",
    "            if current_y == 2 or current_y == 3 or current_y == 4:\n",
    "                reward = -1\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 0)\n"
     ]
    }
   ],
   "source": [
    "r = MarkovDecisionProcess(6,6)\n",
    "s = State(1,1,0)\n",
    "f = Action(1,0)\n",
    "\n",
    "print(r.compute_next_state(0.1, s, f).return_current_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Write a function that returns the reward R(s) given input s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reward_func(self, current_state):\n",
    "    # define the lengh and the width\n",
    "    length = width = 6\n",
    "\n",
    "    # get the current x, y positions -- do not care about heading\n",
    "    current_x, current_y, _ = current_state.return_current_state()\n",
    "\n",
    "    # define the rewards\n",
    "    if current_x == 3 and current_y == 4:\n",
    "        reward = 1\n",
    "    if current_x == 0 or current_x == width-1:\n",
    "        reward = -100\n",
    "    if current_y == 0 or current_y == height-1:\n",
    "        reward = -100\n",
    "    if current_x == 2 or current_x == 4:\n",
    "        if current_y == 2 or current_y == 3 or current_y == 4:\n",
    "            reward = -1\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3a: Create and populate a matrix/array that stores the action a = pi0(s) prescribed by the initial policy pi0 when indexed by state s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy_Matrix:\n",
    "    def __init__(self, given_policy=None):\n",
    "        if given_policy == None:\n",
    "            up = {11, 0, 1}\n",
    "            right = {2, 3, 4}\n",
    "            down = {5, 6, 7}\n",
    "            left = {8, 9, 10}\n",
    "\n",
    "            mat_up    = [[None for x in range(6)] for y in range(6)]\n",
    "            mat_down  = [[None for x in range(6)] for y in range(6)]\n",
    "            mat_left  = [[None for x in range(6)] for y in range(6)]\n",
    "            mat_right = [[None for x in range(6)] for y in range(6)]\n",
    "\n",
    "            rot = 0 # rotation (none-0,left-1,right-2)\n",
    "            mov = 0 # move (none-0,back-1,forward-2)\n",
    "\n",
    "            # populate up matrix\n",
    "            for x in range(6):\n",
    "                for y in range(6):\n",
    "                    # determine rotation\n",
    "                    if (x<3): # goal on right\n",
    "                        rot = 2\n",
    "                    elif (x>3): # goal on left\n",
    "                        rot = 1\n",
    "                    else:\n",
    "                        rot = 0\n",
    "                    # determine move\n",
    "                    if (y<=4):\n",
    "                        mov = 2\n",
    "                    else:\n",
    "                        mov = 1\n",
    "                    # on goal\n",
    "                    if (x==3 and y==4):\n",
    "                        rot = 0\n",
    "                        mov = 0\n",
    "                    mat_up[x][y] = mov, rot\n",
    "\n",
    "            # populate down matrix\n",
    "            for x in range(6):\n",
    "                for y in range(6):\n",
    "                    # determine rotation\n",
    "                    if (x<3): # goal on left\n",
    "                        rot = 1\n",
    "                    elif (x>3): # goal on right\n",
    "                        rot = 2\n",
    "                    else:\n",
    "                        rot = 0\n",
    "                    # determine move\n",
    "                    if (y<=3):\n",
    "                        mov = 1\n",
    "                    else:\n",
    "                        mov = 2\n",
    "                    # on goal\n",
    "                    if (x==3 and y==4):\n",
    "                        rot = 0\n",
    "                        mov = 0\n",
    "                    mat_down[x][y] = mov, rot\n",
    "\n",
    "            # populate right matrix\n",
    "            for x in range(6):\n",
    "                for y in range(6):\n",
    "                    # determine rotation\n",
    "                    if(y>4): # goal on right\n",
    "                        rot = 2\n",
    "                    elif(y<4): # goal on left\n",
    "                        rot = 1\n",
    "                    else:\n",
    "                        rot = 0\n",
    "                    # determine move\n",
    "                    if(x<4):\n",
    "                        mov = 2\n",
    "                    else:\n",
    "                        mov = 1\n",
    "                    # on goal\n",
    "                    if (x==3 and y==4):\n",
    "                        rot = 0\n",
    "                        mov = 0\n",
    "                    mat_right[x][y] = mov, rot\n",
    "\n",
    "            # populate left matrix\n",
    "            for x in range(6):\n",
    "                for y in range(6):\n",
    "                    # determine rotation\n",
    "                    if(y>4): # goal on left\n",
    "                        rot = 1\n",
    "                    elif(y<4): # goal on right\n",
    "                        rot = 2\n",
    "                    else:\n",
    "                        rot = 0\n",
    "                    # determine move\n",
    "                    if(x<3):\n",
    "                        mov = 1\n",
    "                    else:\n",
    "                        mov = 2\n",
    "                    # on goal\n",
    "                    if (x==3 and y==4):\n",
    "                        rot = 0\n",
    "                        mov = 0\n",
    "                    mat_left[x][y] = mov, rot\n",
    "\n",
    "            # matrix for each heading degree\n",
    "            self.pol_mat = [[]]*12\n",
    "            for heading in range(12):\n",
    "                if heading in up:\n",
    "                    self.pol_mat[heading] = mat_up\n",
    "                elif heading in down:\n",
    "                    self.pol_mat[heading] = mat_down\n",
    "                elif heading in left:\n",
    "                    self.pol_mat[heading] = mat_left\n",
    "                else:\n",
    "                    self.pol_mat[heading] = mat_right\n",
    "        else:\n",
    "            self.pol_mat = given_policy\n",
    "            \n",
    "    def policy_action(self, current_state):        \n",
    "        pos_x = current_state.x_position\n",
    "        pos_y = current_state.y_position\n",
    "        heading = current_state.heading\n",
    "        return self.pol_mat[heading][pos_x][pos_y]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pi_0 = Policy_Matrix()\n",
    "#     print(pi_0.pol_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 3b: Write a function to generate and plot a trajectory of a robot given policy matrix/array \u0019, initial state s0, and error probability pe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_trajectory(policy, current_state, prob_of_error):\n",
    "    # initialize the trajectory\n",
    "    full_trajectory = []\n",
    "    # get the current x and y position\n",
    "    current_x, current_y, _ = current_state.return_current_state()\n",
    "    # append the current x and y to the trajectory as an array\n",
    "    full_trajectory.append([current_x, current_y])\n",
    "    \n",
    "    # keep looping till we get to the goal\n",
    "    while current_x != 3 or current_y != 4:\n",
    "        move_from_policy, rotation_from_policy = Policy_Matrix().policy_action(current_state)\n",
    "        if move_from_policy == 0:\n",
    "            move = 0\n",
    "        if move_from_policy == 1:\n",
    "            move = -1\n",
    "        if move_from_policy == 2:\n",
    "            move = 1\n",
    "        if rotation_from_policy == 0:\n",
    "            rotation = 0\n",
    "        if rotation_from_policy == 1:\n",
    "            rotation = -1\n",
    "        if rotation_from_policy == 2:\n",
    "            rotation = 1\n",
    "        action = Action(move, rotation)\n",
    "        next_state = MarkovDecisionProcess(6,6).compute_next_state(prob_of_error, current_state, action)\n",
    "        current_x, current_y, _ = next_state.return_current_state()\n",
    "        full_trajectory.append([current_x, current_y])\n",
    "        current_state = next_state\n",
    "        \n",
    "    return full_trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 0 -1\n",
      "1 3 0 1\n",
      "1 4 1 0\n",
      "2 4 1 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyRBuAEiGcANAMoQbAJL5fx3IpQdGBEHAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112bb3588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pi_0 = Policy_Matrix()\n",
    "current_state = State(1,4,6)\n",
    "full_trajectory = compute_trajectory(pi_0, current_state, 0)\n",
    "plt.xlim(0,6)\n",
    "plt.ylim(0,6)\n",
    "for i in range(len(full_trajectory)-1):\n",
    "#     pass\n",
    "    x,y = full_trajectory[i]\n",
    "    x_one_up, y_one_up = full_trajectory[i+1]\n",
    "    print(x,y,x_one_up-x,y_one_up-y)\n",
    "    plt.arrow(x,y,x_one_up-x,y_one_up-y, head_width=0.1, head_length=0.1,fc='k', ec='k')\n",
    "# plt.arrow(1, 4, 0, -1, head_width=0.05, head_length=0.1, fc='k', ec='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_space = [(-1, -1), (-1, 0), (-1, 1), (0, 0), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "def value_iteration(discount):\n",
    "    prev_V = np.zeros((12, 6, 6)) # previous value matrix\n",
    "    new_pol_mat = [[[None for l in range(6)] for w in range(6)] for h in range(12)] # new policy matrix\n",
    "    err_p = 0 # error probability\n",
    "    conv = 0 # convergence boolean\n",
    "    \n",
    "    while (conv != 1):\n",
    "        new_V = np.zeros((12, 6, 6)) # new value matrix\n",
    "        for x_pos in range(6):\n",
    "            for y_pos in range(6):\n",
    "                for heading in range(12):\n",
    "                    current_state = State(x_pos, y_pos, heading)\n",
    "                    poss_states = calc_adj_states(current_state)\n",
    "                    best_action = None\n",
    "                    print(heading, x_pos, y_pos)\n",
    "                    max_action_val = float('-inf')\n",
    "                    for act in action_space:\n",
    "                        action = Action(act[0], act[1]) # create action object for transition probability calculation\n",
    "                        action_val = 0\n",
    "                        for next_state in poss_states:\n",
    "                            x_, y_, h_ = next_state.return_current_state()\n",
    "                            mdp = MarkovDecisionProcess(6,6)\n",
    "                            \n",
    "                            action_val += mdp.transition_probabilities(err_p, action, current_state, next_state) * (mdp.reward(current_state) + discount*prev_V[h_][x_][y_])\n",
    "                        if (action_val > max_action_val):\n",
    "                            max_action_val = action_val\n",
    "                            best_action = action\n",
    "                    # update policy matrix and new value matrix\n",
    "                    new_pol_mat[heading][x_pos][y_pos] = best_action\n",
    "                    new_V[heading][x_pos][y_pos] = max_action_val\n",
    "        \n",
    "        # check if convergence occurs\n",
    "        if(np.equal(new_V, prev_V)):\n",
    "            break\n",
    "        # if not, update value matrix\n",
    "        prev_v = new_V\n",
    "    # create final policy\n",
    "    new_pol = Policy(new_pol_mat)\n",
    "    return new_pol\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# calculate adjacent states\n",
    "def calc_adj_states(current_state):\n",
    "    x = current_state.x_position\n",
    "    y = current_state.y_position\n",
    "    h = current_state.heading\n",
    "    \n",
    "    poss_h = [h,  (h+1) % 12, (h-1) % 12, (h+2) % 12, (h-2) % 12] # five possible headings\n",
    "    poss_x = [x] # first possibility is not moving\n",
    "    poss_y = [y] # first possibility is not moving\n",
    "    \n",
    "    # down, up, left, right\n",
    "    if (x-1 >= 0):\n",
    "        poss_x.append(x-1)\n",
    "    if (x+1 <= 6):\n",
    "        poss_x.append(x+1)\n",
    "    if (y-1 >= 0):\n",
    "        poss_x.append(y-1)\n",
    "    if (y+1 <= 6):\n",
    "        poss_x.append(y+1)        \n",
    "    \n",
    "    adj_states = []\n",
    "    for x_ in poss_x:\n",
    "        for y_ in poss_y:\n",
    "            for h_ in poss_h:\n",
    "                adj_states.append(State(x_,y_,h_))\n",
    "    return adj_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing value iteration function\n",
    "discount = 0.9\n",
    "# opt_pol = value_iteration(discount)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
