{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A: Initializing the state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    \n",
    "    def __init__(self, x_position, y_position, heading):\n",
    "        self.x_position = x_position\n",
    "        self.y_position = y_position\n",
    "        self.heading = heading\n",
    "        \n",
    "    def return_current_state(self):\n",
    "        return self.x_position, self.y_position, self.heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B: Initializing the action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    \n",
    "    def __init__(self, move, rotation):\n",
    "        self.move = move\n",
    "        self.rotation = rotation\n",
    "        \n",
    "    def return_action(self):\n",
    "        return self.move, self.rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1C: Return the probabilty Psa(s') given pe, s, a, s'\n",
    "## 1D: return a next state s' given error probability pe, s, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### This is the Markov decision process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovDecisionProcess:\n",
    "    \n",
    "    # get the length and the width of the space that we are in\n",
    "    def __init__(self, length, width):\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "    \n",
    "    # check for bound violations\n",
    "    def check_bounds(self, next_x, next_y, current_x, current_y):\n",
    "        if (next_x < 0 or next_x >= self.width):\n",
    "            next_x = current_x\n",
    "        if (next_y < 0 or next_y >= self.length):\n",
    "            next_y = current_y\n",
    "        return next_x, next_y\n",
    "    \n",
    "    #define the directions\n",
    "    left = {8,9,10}\n",
    "    right = {2,3,4}\n",
    "    up = {11,0,1}\n",
    "    down = {5,6,7}\n",
    "    \n",
    "    # find out the next step --> returns next_x, next_y, next_heading\n",
    "    def next_state_compiled(self, state, action):\n",
    "        # get x, y and heading from state\n",
    "        current_x = state.x_position\n",
    "        current_y = state.y_position\n",
    "        current_heading = state.heading\n",
    "        \n",
    "        # get move and rotation from action\n",
    "        move = action.move\n",
    "        rotation = action.rotation\n",
    "        \n",
    "        # check if heading is left, need to only change x and not y\n",
    "        if current_heading in self.left:\n",
    "            next_x = current_x - move\n",
    "            next_y = current_y\n",
    "        \n",
    "        # check if heading is right, need to only change x and not y\n",
    "        elif current_heading in self.right:\n",
    "            next_x = current_x + move\n",
    "            next_y = current_y\n",
    "        \n",
    "        # check if heading is up, need to only change y and not x\n",
    "        elif current_heading in self.up:\n",
    "            next_x = current_x\n",
    "            next_y = current_y + move\n",
    "        \n",
    "        # check if heading is down, need to only change y and not x\n",
    "        else:\n",
    "            next_x = current_x\n",
    "            next_y = current_y - move\n",
    "        \n",
    "        # need to check the bounds\n",
    "        next_x, next_y = self.check_bounds(next_x, next_y, current_x, current_y)\n",
    "        \n",
    "        # finally, need to accomodate for the rotation in heading\n",
    "        next_heading = (current_heading + rotation) % 12\n",
    "        \n",
    "        return next_x, next_y, next_heading\n",
    "    \n",
    "    # find out the next step for the movements that have the prob of error\n",
    "    def next_state_individualized(self, current_x, current_y, current_heading, move, rotation):\n",
    "        # check if heading is left, need to only change x and not y\n",
    "        if current_heading in self.left:\n",
    "            next_x = current_x - move\n",
    "            next_y = current_y\n",
    "        \n",
    "        # check if heading is right, need to only change x and not y\n",
    "        elif current_heading in self.right:\n",
    "            next_x = current_x + move\n",
    "            next_y = current_y\n",
    "        \n",
    "        # check if heading is up, need to only change y and not x\n",
    "        elif current_heading in self.up:\n",
    "            next_x = current_x\n",
    "            next_y = current_y + move\n",
    "        \n",
    "        # check if heading is down, need to only change y and not x\n",
    "        else:\n",
    "            next_x = current_x\n",
    "            next_y = current_y - move\n",
    "        \n",
    "        # need to check the bounds\n",
    "        \n",
    "        next_x, next_y = self.check_bounds(next_x, next_y, current_x, current_y)\n",
    "        \n",
    "        # finally, need to accomodate for the rotation in heading\n",
    "        next_heading = (current_heading + rotation) % 12\n",
    "        \n",
    "        return next_x, next_y, next_heading\n",
    "    \n",
    "    # find out the transition probabilities\n",
    "    def transition_probabilities(self, prob_of_error, action, current_state, next_state):\n",
    "        # get move and rotation from action\n",
    "        move = action.move\n",
    "        rotation = action.rotation\n",
    "        \n",
    "        # if we do not move, current state should equal next state. \n",
    "        if move == 0:\n",
    "            if current_state.return_current_state() == next_state.return_current_state():\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "        # in the case that we do move, need to account for the error probabilities\n",
    "        \n",
    "        if next_state.return_current_state() == self.next_state_compiled(current_state, action):\n",
    "            return 1-(2*prob_of_error)\n",
    "        else:\n",
    "            current_x = current_state.x_position\n",
    "            current_y = current_state.y_position\n",
    "            current_heading = current_state.heading\n",
    "\n",
    "            # need to check to return the prob of error\n",
    "            if next_state.return_current_state() == self.next_state_individualized(current_x, current_y, (current_heading-1)%12, move, rotation):\n",
    "                return prob_of_error\n",
    "\n",
    "            if next_state.return_current_state() == self.next_state_individualized(current_x, current_y, (current_heading+1)%12, move, rotation):\n",
    "                return prob_of_error\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    number_of_headings = 12\n",
    "    \n",
    "    # Part 1D\n",
    "    def compute_next_state(self, prob_of_error, current_state, action):\n",
    "        \n",
    "        wrong_states = []\n",
    "        # need to loop through all of the values of x, y and heading\n",
    "        for i in range(self.length):\n",
    "            for j in range(self.width):\n",
    "                for k in range(self.number_of_headings):\n",
    "                    # define the next state\n",
    "                    next_state = State(i,j,k)\n",
    "                    # find the transition probability between current state and the next state\n",
    "                    prob_of_transition = self.transition_probabilities(prob_of_error, action, current_state, next_state)\n",
    "                    # if the probability of transitioning does not equal 0, then only do we proceed. If 0, do not care\n",
    "                    if prob_of_transition != 0:\n",
    "                        # if our transition probabilty is the probability of error, it means that there was an error. Need to keep track of these next state values\n",
    "                        if prob_of_transition == prob_of_error:\n",
    "                            wrong_states.append(next_state)\n",
    "                        else:\n",
    "                            correct_next_state = next_state\n",
    "        # if I choose a random number between 0 and 1 and my number is less than 2*prob_of_error, I move in the wrong direction. If not, I move in the correct direction.\n",
    "        random_number_generated = np.random.uniform(0,1)\n",
    "        if random_number_generated < 2*prob_of_error:\n",
    "            random_index = random.randrange(len(wrong_states))\n",
    "            return wrong_states[random_index]\n",
    "        else:\n",
    "            return correct_next_state\n",
    "    def reward(self, current_state):\n",
    "        # define the lengh and the width\n",
    "        length = width = 6\n",
    "\n",
    "        # get the current x, y positions -- do not care about heading\n",
    "        current_x, current_y, _ = current_state.return_current_state()\n",
    "\n",
    "        # define the rewards\n",
    "        if current_x == 3 and current_y == 4:\n",
    "            reward = 1\n",
    "        if current_x == 0 or current_x == width-1:\n",
    "            reward = -100\n",
    "        if current_y == 0 or current_y == length-1:\n",
    "            reward = -100\n",
    "        if current_x == 2 or current_x == 4:\n",
    "            if current_y == 2 or current_y == 3 or current_y == 4:\n",
    "                reward = -1\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 0)\n"
     ]
    }
   ],
   "source": [
    "r = MarkovDecisionProcess(6,6)\n",
    "s = State(1,1,0)\n",
    "f = Action(1,0)\n",
    "\n",
    "print(r.compute_next_state(0.1, s, f).return_current_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Write a function that returns the reward R(s) given input s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(self, current_state):\n",
    "    # define the lengh and the width\n",
    "    length = width = 6\n",
    "\n",
    "    # get the current x, y positions -- do not care about heading\n",
    "    current_x, current_y, _ = current_state.return_current_state()\n",
    "\n",
    "    # define the rewards\n",
    "    if current_x == 3 and current_y == 4:\n",
    "        reward = 1\n",
    "    if current_x == 0 or current_x == width-1:\n",
    "        reward = -100\n",
    "    if current_y == 0 or current_y == height-1:\n",
    "        reward = -100\n",
    "    if current_x == 2 or current_x == 4:\n",
    "        if current_y == 2 or current_y == 3 or current_y == 4:\n",
    "            reward = -1\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3a: Create and populate a matrix/array that stores the action a = pi0(s) prescribed by the initial policy pi0 when indexed by state s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_Matrix:\n",
    "    def __init__(self, given_policy=None):\n",
    "        if given_policy == None:\n",
    "            up = {11, 0, 1}\n",
    "            right = {2, 3, 4}\n",
    "            down = {5, 6, 7}\n",
    "            left = {8, 9, 10}\n",
    "\n",
    "            mat_up    = [[None for x in range(6)] for y in range(6)]\n",
    "            mat_down  = [[None for x in range(6)] for y in range(6)]\n",
    "            mat_left  = [[None for x in range(6)] for y in range(6)]\n",
    "            mat_right = [[None for x in range(6)] for y in range(6)]\n",
    "\n",
    "            rot = 0 # rotation (none-0,left-1,right-2)\n",
    "            mov = 0 # move (none-0,back-1,forward-2)\n",
    "\n",
    "            # populate up matrix\n",
    "            for x in range(6):\n",
    "                for y in range(6):\n",
    "                    # determine rotation\n",
    "                    if (x<3): # goal on right\n",
    "                        rot = 2\n",
    "                    elif (x>3): # goal on left\n",
    "                        rot = 1\n",
    "                    else:\n",
    "                        rot = 0\n",
    "                    # determine move\n",
    "                    if (y<=4):\n",
    "                        mov = 2\n",
    "                    else:\n",
    "                        mov = 1\n",
    "                    # on goal\n",
    "                    if (x==3 and y==4):\n",
    "                        rot = 0\n",
    "                        mov = 0\n",
    "                    mat_up[x][y] = mov, rot\n",
    "\n",
    "            # populate down matrix\n",
    "            for x in range(6):\n",
    "                for y in range(6):\n",
    "                    # determine rotation\n",
    "                    if (x<3): # goal on left\n",
    "                        rot = 1\n",
    "                    elif (x>3): # goal on right\n",
    "                        rot = 2\n",
    "                    else:\n",
    "                        rot = 0\n",
    "                    # determine move\n",
    "                    if (y<=3):\n",
    "                        mov = 1\n",
    "                    else:\n",
    "                        mov = 2\n",
    "                    # on goal\n",
    "                    if (x==3 and y==4):\n",
    "                        rot = 0\n",
    "                        mov = 0\n",
    "                    mat_down[x][y] = mov, rot\n",
    "\n",
    "            # populate right matrix\n",
    "            for x in range(6):\n",
    "                for y in range(6):\n",
    "                    # determine rotation\n",
    "                    if(y>4): # goal on right\n",
    "                        rot = 2\n",
    "                    elif(y<4): # goal on left\n",
    "                        rot = 1\n",
    "                    else:\n",
    "                        rot = 0\n",
    "                    # determine move\n",
    "                    if(x<4):\n",
    "                        mov = 2\n",
    "                    else:\n",
    "                        mov = 1\n",
    "                    # on goal\n",
    "                    if (x==3 and y==4):\n",
    "                        rot = 0\n",
    "                        mov = 0\n",
    "                    mat_right[x][y] = mov, rot\n",
    "\n",
    "            # populate left matrix\n",
    "            for x in range(6):\n",
    "                for y in range(6):\n",
    "                    # determine rotation\n",
    "                    if(y>4): # goal on left\n",
    "                        rot = 1\n",
    "                    elif(y<4): # goal on right\n",
    "                        rot = 2\n",
    "                    else:\n",
    "                        rot = 0\n",
    "                    # determine move\n",
    "                    if(x<3):\n",
    "                        mov = 1\n",
    "                    else:\n",
    "                        mov = 2\n",
    "                    # on goal\n",
    "                    if (x==3 and y==4):\n",
    "                        rot = 0\n",
    "                        mov = 0\n",
    "                    mat_left[x][y] = mov, rot\n",
    "\n",
    "            # matrix for each heading degree\n",
    "            self.pol_mat = [[]]*12\n",
    "            for heading in range(12):\n",
    "                if heading in up:\n",
    "                    self.pol_mat[heading] = mat_up\n",
    "                elif heading in down:\n",
    "                    self.pol_mat[heading] = mat_down\n",
    "                elif heading in left:\n",
    "                    self.pol_mat[heading] = mat_left\n",
    "                else:\n",
    "                    self.pol_mat[heading] = mat_right\n",
    "        else:\n",
    "            self.pol_mat = given_policy\n",
    "            \n",
    "    def policy_action(self, current_state):        \n",
    "        pos_x = current_state.x_position\n",
    "        pos_y = current_state.y_position\n",
    "        heading = current_state.heading\n",
    "        return self.pol_mat[heading][pos_x][pos_y]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pi_0 = Policy_Matrix()\n",
    "#     print(pi_0.pol_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 3b: Write a function to generate and plot a trajectory of a robot given policy matrix/array \u0019, initial state s0, and error probability pe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trajectory(policy, current_state, prob_of_error):\n",
    "    # initialize the trajectory\n",
    "    full_trajectory = []\n",
    "    # get the current x and y position\n",
    "    current_x, current_y, _ = current_state.return_current_state()\n",
    "    # append the current x and y to the trajectory as an array\n",
    "    full_trajectory.append([current_x, current_y])\n",
    "    \n",
    "    # keep looping till we get to the goal\n",
    "    while current_x != 3 or current_y != 4:\n",
    "        move_from_policy, rotation_from_policy = Policy_Matrix().policy_action(current_state)\n",
    "        if move_from_policy == 0:\n",
    "            move = 0\n",
    "        if move_from_policy == 1:\n",
    "            move = -1\n",
    "        if move_from_policy == 2:\n",
    "            move = 1\n",
    "        if rotation_from_policy == 0:\n",
    "            rotation = 0\n",
    "        if rotation_from_policy == 1:\n",
    "            rotation = -1\n",
    "        if rotation_from_policy == 2:\n",
    "            rotation = 1\n",
    "        action = Action(move, rotation)\n",
    "        next_state = MarkovDecisionProcess(6,6).compute_next_state(prob_of_error, current_state, action)\n",
    "        current_x, current_y, _ = next_state.return_current_state()\n",
    "        full_trajectory.append([current_x, current_y])\n",
    "        print(full_trajectory)\n",
    "        current_state = next_state\n",
    "        \n",
    "    \n",
    "    # to plot the trajectory, we need to plot out the full trajectory\n",
    "    for x,y in full_trajectory:\n",
    "        plt.scatter(x,y,marker=\"o\", color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4], [1, 3]]\n",
      "[[1, 4], [1, 3], [1, 4]]\n",
      "[[1, 4], [1, 3], [1, 4], [2, 4]]\n",
      "[[1, 4], [1, 3], [1, 4], [2, 4], [3, 4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc69f2b9c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pi_0 = Policy_Matrix()\n",
    "current_state = State(1,4,6)\n",
    "compute_trajectory(pi_0, current_state, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = [(-1, -1), (-1, 0), (-1, 1), (0, 0), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "def value_iteration(discount):\n",
    "    prev_V = np.zeros((12, 6, 6)) # previous value matrix\n",
    "    new_pol_mat = [[[None for l in range(6)] for w in range(6)] for h in range(12)] # new policy matrix\n",
    "    err_p = 0 # error probability\n",
    "    conv = 0 # convergence boolean\n",
    "    \n",
    "    while (conv != 1):\n",
    "        new_V = np.zeros((12, 6, 6)) # new value matrix\n",
    "        for x_pos in range(6):\n",
    "            for y_pos in range(6):\n",
    "                for heading in range(12):\n",
    "                    current_state = State(x_pos, y_pos, heading)\n",
    "                    poss_states = calc_adj_states(current_state)\n",
    "                    best_action = None\n",
    "                    print(heading, x_pos, y_pos)\n",
    "                    max_action_val = float('-inf')\n",
    "                    for act in action_space:\n",
    "                        action = Action(act[0], act[1]) # create action object for transition probability calculation\n",
    "                        action_val = 0\n",
    "                        for next_state in poss_states:\n",
    "                            x_, y_, h_ = next_state.return_current_state()\n",
    "                            mdp = MarkovDecisionProcess(6,6)\n",
    "                            \n",
    "                            action_val += mdp.transition_probabilities(err_p, action, current_state, next_state) * (mdp.reward(current_state) + discount*prev_V[h_][x_][y_])\n",
    "                        if (action_val > max_action_val):\n",
    "                            max_action_val = action_val\n",
    "                            best_action = action\n",
    "                    # update policy matrix and new value matrix\n",
    "                    new_pol_mat[heading][x_pos][y_pos] = best_action\n",
    "                    new_V[heading][x_pos][y_pos] = max_action_val\n",
    "        \n",
    "        # check if convergence occurs\n",
    "        if(np.equal(new_V, prev_V)):\n",
    "            break\n",
    "        # if not, update value matrix\n",
    "        prev_v = new_V\n",
    "    # create final policy\n",
    "    new_pol = Policy(new_pol_mat)\n",
    "    return new_pol\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# calculate adjacent states\n",
    "def calc_adj_states(current_state):\n",
    "    x = current_state.x_position\n",
    "    y = current_state.y_position\n",
    "    h = current_state.heading\n",
    "    \n",
    "    poss_h = [h,  (h+1) % 12, (h-1) % 12, (h+2) % 12, (h-2) % 12] # five possible headings\n",
    "    poss_x = [x] # first possibility is not moving\n",
    "    poss_y = [y] # first possibility is not moving\n",
    "    \n",
    "    # down, up, left, right\n",
    "    if (x-1 >= 0):\n",
    "        poss_x.append(x-1)\n",
    "    if (x+1 <= 6):\n",
    "        poss_x.append(x+1)\n",
    "    if (y-1 >= 0):\n",
    "        poss_x.append(y-1)\n",
    "    if (y+1 <= 6):\n",
    "        poss_x.append(y+1)        \n",
    "    \n",
    "    adj_states = []\n",
    "    for x_ in poss_x:\n",
    "        for y_ in poss_y:\n",
    "            for h_ in poss_h:\n",
    "                adj_states.append(State(x_,y_,h_))\n",
    "    return adj_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing value iteration function\n",
    "discount = 0.9\n",
    "# opt_pol = value_iteration(discount)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
